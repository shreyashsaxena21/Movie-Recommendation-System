{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3c11c1f2",
   "metadata": {},
   "source": [
    "#Task to follow:-\n",
    "1. What is linearity in linear regression\n",
    "2. Impact of outliers in machine learning models.\n",
    "3. Feature scaling techniques\n",
    "4. What are the common problems with decision tree and how to overcome it\n",
    "Practical to perform \n",
    "1. Feature scaling on knn dataset\n",
    "2. Gridsearch cv on Random forest dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbac5b",
   "metadata": {},
   "source": [
    "1.Linearity in linear regression refers to the assumption that there is a linear relationship between the independent variable(s) (predictor variable(s)) and the dependent variable (response variable). In other words, it assumes that the change in the dependent variable is proportional to the change in the independent variable(s).\n",
    "* Here, the linearity assumption implies that the relationship between the dependent variable and each independent variable is linear, and any change in the dependent variable is proportional to the changes in the independent variables.\n",
    "\n",
    "2.Outliers are data points that deviate significantly from the rest of the data in a dataset. In machine learning models, outliers can have various impacts, which depend on the type of model and the nature of the data.\n",
    "* Outliers can have a significant impact on the performance of machine learning models. They can affect the accuracy of the models and lead to incorrect predictions. For example, in a regression model, outliers can result in a significant deviation from the true line of best fit, leading to inaccurate predictions\n",
    "* Outliers can also affect the training of machine learning models. When outliers are present in the training set, the model can become overly sensitive to these points, leading to overfitting. Overfitting occurs when the model becomes too complex and fits the training data too closely, leading to poor performance on new, unseen data.\n",
    "\n",
    "3.Feature scaling is a data preprocessing technique used to transform the values of features or variables in a dataset to a similar scale. The purpose is to ensure that all features contribute equally to the model and to avoid the domination of features with larger values.\n",
    "Feature scaling becomes necessary when dealing with datasets containing features that have different ranges, units of measurement, or orders of magnitude. In such cases, the variation in feature values can lead to biased model performance or difficulties during the learning process.\n",
    "* 2 techinques-\n",
    "->Normalization:Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1\n",
    "->standardization:Centers data around the mean and scales to a standard deviation of 1.\n",
    "\n",
    "\n",
    "4. It is a versatile supervised machine-learning algorithm, which is used for both classification and regression problems. It is one of the very powerful algorithms. And it is also used in Random Forest to train on different subsets of training data.\n",
    "\n",
    "* Overfitting:\n",
    "Overfitting refers to the condition when the model completely fits the training data but fails to generalize the testing unseen data. Overfit condition arises when the model memorizes the noise of the training data and fails to capture important patterns\n",
    "\n",
    "->Problem: Decision trees are prone to overfitting, creating complex and deep trees that capture noise in the training data.\n",
    "->Solution:\n",
    "Pruning:Pruning refers to a technique to remove the parts of the decision tree to prevent growing to its full depth. By tuning the hyperparameters of the decision tree model one can prune the trees and prevent them from overfitting.\n",
    "Apply techniques like post-pruning (removing branches) or pre-pruning (limiting the tree's depth) to prevent excessive growth. \n",
    "Minimum Samples per Leaf: Set a minimum number of samples required to create a leaf node, preventing small subsets of data from being split.\n",
    "\n",
    "* Bias towards Dominant Features:\n",
    "\n",
    "Problem: Decision trees tend to favor features with more levels or categories, resulting in biased splits.\n",
    "Solution: Use algorithms that account for feature importance, like Random Forests, which average the decisions of multiple trees.\n",
    "\n",
    "* Categorical vs. Numerical Features:\n",
    "\n",
    "Problem: Decision trees might not handle categorical and numerical features equally well.\n",
    "Solution: Some algorithms, like Random Forests, handle both types of features effectively, while others might require preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ab039",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850d9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a545dd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XVPM</th>\n",
       "      <th>GWYH</th>\n",
       "      <th>TRAT</th>\n",
       "      <th>TLLZ</th>\n",
       "      <th>IGGA</th>\n",
       "      <th>HYKR</th>\n",
       "      <th>EDFS</th>\n",
       "      <th>GUUB</th>\n",
       "      <th>MGJM</th>\n",
       "      <th>JHZC</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1636.670614</td>\n",
       "      <td>817.988525</td>\n",
       "      <td>2565.995189</td>\n",
       "      <td>358.347163</td>\n",
       "      <td>550.417491</td>\n",
       "      <td>1618.870897</td>\n",
       "      <td>2147.641254</td>\n",
       "      <td>330.727893</td>\n",
       "      <td>1494.878631</td>\n",
       "      <td>845.136088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013.402760</td>\n",
       "      <td>577.587332</td>\n",
       "      <td>2644.141273</td>\n",
       "      <td>280.428203</td>\n",
       "      <td>1161.873391</td>\n",
       "      <td>2084.107872</td>\n",
       "      <td>853.404981</td>\n",
       "      <td>447.157619</td>\n",
       "      <td>1193.032521</td>\n",
       "      <td>861.081809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300.035501</td>\n",
       "      <td>820.518697</td>\n",
       "      <td>2025.854469</td>\n",
       "      <td>525.562292</td>\n",
       "      <td>922.206261</td>\n",
       "      <td>2552.355407</td>\n",
       "      <td>818.676686</td>\n",
       "      <td>845.491492</td>\n",
       "      <td>1968.367513</td>\n",
       "      <td>1647.186291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1059.347542</td>\n",
       "      <td>1066.866418</td>\n",
       "      <td>612.000041</td>\n",
       "      <td>480.827789</td>\n",
       "      <td>419.467495</td>\n",
       "      <td>685.666983</td>\n",
       "      <td>852.867810</td>\n",
       "      <td>341.664784</td>\n",
       "      <td>1154.391368</td>\n",
       "      <td>1450.935357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.340526</td>\n",
       "      <td>1313.679056</td>\n",
       "      <td>950.622661</td>\n",
       "      <td>724.742174</td>\n",
       "      <td>843.065903</td>\n",
       "      <td>1370.554164</td>\n",
       "      <td>905.469453</td>\n",
       "      <td>658.118202</td>\n",
       "      <td>539.459350</td>\n",
       "      <td>1899.850792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1343.060600</td>\n",
       "      <td>1289.142057</td>\n",
       "      <td>407.307449</td>\n",
       "      <td>567.564764</td>\n",
       "      <td>1000.953905</td>\n",
       "      <td>919.602401</td>\n",
       "      <td>485.269059</td>\n",
       "      <td>668.007397</td>\n",
       "      <td>1124.772996</td>\n",
       "      <td>2127.628290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>938.847057</td>\n",
       "      <td>1142.884331</td>\n",
       "      <td>2096.064295</td>\n",
       "      <td>483.242220</td>\n",
       "      <td>522.755771</td>\n",
       "      <td>1703.169782</td>\n",
       "      <td>2007.548635</td>\n",
       "      <td>533.514816</td>\n",
       "      <td>379.264597</td>\n",
       "      <td>567.200545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>921.994822</td>\n",
       "      <td>607.996901</td>\n",
       "      <td>2065.482529</td>\n",
       "      <td>497.107790</td>\n",
       "      <td>457.430427</td>\n",
       "      <td>1577.506205</td>\n",
       "      <td>1659.197738</td>\n",
       "      <td>186.854577</td>\n",
       "      <td>978.340107</td>\n",
       "      <td>1943.304912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1157.069348</td>\n",
       "      <td>602.749160</td>\n",
       "      <td>1548.809995</td>\n",
       "      <td>646.809528</td>\n",
       "      <td>1335.737820</td>\n",
       "      <td>1455.504390</td>\n",
       "      <td>2788.366441</td>\n",
       "      <td>552.388107</td>\n",
       "      <td>1264.818079</td>\n",
       "      <td>1331.879020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1287.150025</td>\n",
       "      <td>1303.600085</td>\n",
       "      <td>2247.287535</td>\n",
       "      <td>664.362479</td>\n",
       "      <td>1132.682562</td>\n",
       "      <td>991.774941</td>\n",
       "      <td>2007.676371</td>\n",
       "      <td>251.916948</td>\n",
       "      <td>846.167511</td>\n",
       "      <td>952.895751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            XVPM         GWYH         TRAT        TLLZ         IGGA  \\\n",
       "0    1636.670614   817.988525  2565.995189  358.347163   550.417491   \n",
       "1    1013.402760   577.587332  2644.141273  280.428203  1161.873391   \n",
       "2    1300.035501   820.518697  2025.854469  525.562292   922.206261   \n",
       "3    1059.347542  1066.866418   612.000041  480.827789   419.467495   \n",
       "4    1018.340526  1313.679056   950.622661  724.742174   843.065903   \n",
       "..           ...          ...          ...         ...          ...   \n",
       "995  1343.060600  1289.142057   407.307449  567.564764  1000.953905   \n",
       "996   938.847057  1142.884331  2096.064295  483.242220   522.755771   \n",
       "997   921.994822   607.996901  2065.482529  497.107790   457.430427   \n",
       "998  1157.069348   602.749160  1548.809995  646.809528  1335.737820   \n",
       "999  1287.150025  1303.600085  2247.287535  664.362479  1132.682562   \n",
       "\n",
       "            HYKR         EDFS        GUUB         MGJM         JHZC  \\\n",
       "0    1618.870897  2147.641254  330.727893  1494.878631   845.136088   \n",
       "1    2084.107872   853.404981  447.157619  1193.032521   861.081809   \n",
       "2    2552.355407   818.676686  845.491492  1968.367513  1647.186291   \n",
       "3     685.666983   852.867810  341.664784  1154.391368  1450.935357   \n",
       "4    1370.554164   905.469453  658.118202   539.459350  1899.850792   \n",
       "..           ...          ...         ...          ...          ...   \n",
       "995   919.602401   485.269059  668.007397  1124.772996  2127.628290   \n",
       "996  1703.169782  2007.548635  533.514816   379.264597   567.200545   \n",
       "997  1577.506205  1659.197738  186.854577   978.340107  1943.304912   \n",
       "998  1455.504390  2788.366441  552.388107  1264.818079  1331.879020   \n",
       "999   991.774941  2007.676371  251.916948   846.167511   952.895751   \n",
       "\n",
       "     TARGET CLASS  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "995             0  \n",
       "996             1  \n",
       "997             1  \n",
       "998             1  \n",
       "999             1  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"E:\\internship\\KNN_Project_Data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb97c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e542e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVPM            0\n",
       "GWYH            0\n",
       "TRAT            0\n",
       "TLLZ            0\n",
       "IGGA            0\n",
       "HYKR            0\n",
       "EDFS            0\n",
       "GUUB            0\n",
       "MGJM            0\n",
       "JHZC            0\n",
       "TARGET CLASS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68af6ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "834bb53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   XVPM          1000 non-null   float64\n",
      " 1   GWYH          1000 non-null   float64\n",
      " 2   TRAT          1000 non-null   float64\n",
      " 3   TLLZ          1000 non-null   float64\n",
      " 4   IGGA          1000 non-null   float64\n",
      " 5   HYKR          1000 non-null   float64\n",
      " 6   EDFS          1000 non-null   float64\n",
      " 7   GUUB          1000 non-null   float64\n",
      " 8   MGJM          1000 non-null   float64\n",
      " 9   JHZC          1000 non-null   float64\n",
      " 10  TARGET CLASS  1000 non-null   int64  \n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 86.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6991a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XVPM</th>\n",
       "      <th>GWYH</th>\n",
       "      <th>TRAT</th>\n",
       "      <th>TLLZ</th>\n",
       "      <th>IGGA</th>\n",
       "      <th>HYKR</th>\n",
       "      <th>EDFS</th>\n",
       "      <th>GUUB</th>\n",
       "      <th>MGJM</th>\n",
       "      <th>JHZC</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1055.071157</td>\n",
       "      <td>991.851567</td>\n",
       "      <td>1529.373525</td>\n",
       "      <td>495.107156</td>\n",
       "      <td>940.590072</td>\n",
       "      <td>1550.637455</td>\n",
       "      <td>1561.003252</td>\n",
       "      <td>561.346117</td>\n",
       "      <td>1089.067338</td>\n",
       "      <td>1452.521629</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>370.980193</td>\n",
       "      <td>392.278890</td>\n",
       "      <td>640.286092</td>\n",
       "      <td>142.789188</td>\n",
       "      <td>345.923136</td>\n",
       "      <td>493.491988</td>\n",
       "      <td>598.608517</td>\n",
       "      <td>247.357552</td>\n",
       "      <td>402.666953</td>\n",
       "      <td>568.132005</td>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.720000</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>8.450000</td>\n",
       "      <td>17.930000</td>\n",
       "      <td>27.930000</td>\n",
       "      <td>31.960000</td>\n",
       "      <td>13.520000</td>\n",
       "      <td>23.210000</td>\n",
       "      <td>30.890000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>767.413366</td>\n",
       "      <td>694.859326</td>\n",
       "      <td>1062.600806</td>\n",
       "      <td>401.788135</td>\n",
       "      <td>700.763295</td>\n",
       "      <td>1219.267077</td>\n",
       "      <td>1132.097865</td>\n",
       "      <td>381.704293</td>\n",
       "      <td>801.849802</td>\n",
       "      <td>1059.499689</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1045.904805</td>\n",
       "      <td>978.355081</td>\n",
       "      <td>1522.507269</td>\n",
       "      <td>500.197421</td>\n",
       "      <td>939.348662</td>\n",
       "      <td>1564.996551</td>\n",
       "      <td>1565.882879</td>\n",
       "      <td>540.420379</td>\n",
       "      <td>1099.087954</td>\n",
       "      <td>1441.554053</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1326.065178</td>\n",
       "      <td>1275.528770</td>\n",
       "      <td>1991.128626</td>\n",
       "      <td>600.525709</td>\n",
       "      <td>1182.578166</td>\n",
       "      <td>1891.937040</td>\n",
       "      <td>1981.739411</td>\n",
       "      <td>725.762027</td>\n",
       "      <td>1369.923665</td>\n",
       "      <td>1864.405512</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2117.000000</td>\n",
       "      <td>2172.000000</td>\n",
       "      <td>3180.000000</td>\n",
       "      <td>845.000000</td>\n",
       "      <td>1793.000000</td>\n",
       "      <td>2793.000000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>1352.000000</td>\n",
       "      <td>2321.000000</td>\n",
       "      <td>3089.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              XVPM         GWYH         TRAT         TLLZ         IGGA  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean   1055.071157   991.851567  1529.373525   495.107156   940.590072   \n",
       "std     370.980193   392.278890   640.286092   142.789188   345.923136   \n",
       "min      21.170000    21.720000    31.800000     8.450000    17.930000   \n",
       "25%     767.413366   694.859326  1062.600806   401.788135   700.763295   \n",
       "50%    1045.904805   978.355081  1522.507269   500.197421   939.348662   \n",
       "75%    1326.065178  1275.528770  1991.128626   600.525709  1182.578166   \n",
       "max    2117.000000  2172.000000  3180.000000   845.000000  1793.000000   \n",
       "\n",
       "              HYKR         EDFS         GUUB         MGJM         JHZC  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean   1550.637455  1561.003252   561.346117  1089.067338  1452.521629   \n",
       "std     493.491988   598.608517   247.357552   402.666953   568.132005   \n",
       "min      27.930000    31.960000    13.520000    23.210000    30.890000   \n",
       "25%    1219.267077  1132.097865   381.704293   801.849802  1059.499689   \n",
       "50%    1564.996551  1565.882879   540.420379  1099.087954  1441.554053   \n",
       "75%    1891.937040  1981.739411   725.762027  1369.923665  1864.405512   \n",
       "max    2793.000000  3196.000000  1352.000000  2321.000000  3089.000000   \n",
       "\n",
       "       TARGET CLASS  \n",
       "count    1000.00000  \n",
       "mean        0.50000  \n",
       "std         0.50025  \n",
       "min         0.00000  \n",
       "25%         0.00000  \n",
       "50%         0.50000  \n",
       "75%         1.00000  \n",
       "max         1.00000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27450c0e",
   "metadata": {},
   "source": [
    "# scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9fb7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(df.drop('TARGET CLASS',axis=1))\n",
    "scaled=sc.transform(df.drop('TARGET CLASS',axis=1))\n",
    "scaled\n",
    "scaleddf=pd.DataFrame(scaled,columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982e638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af011a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XVPM</th>\n",
       "      <th>GWYH</th>\n",
       "      <th>TRAT</th>\n",
       "      <th>TLLZ</th>\n",
       "      <th>IGGA</th>\n",
       "      <th>HYKR</th>\n",
       "      <th>EDFS</th>\n",
       "      <th>GUUB</th>\n",
       "      <th>MGJM</th>\n",
       "      <th>JHZC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.568522</td>\n",
       "      <td>-0.443435</td>\n",
       "      <td>1.619808</td>\n",
       "      <td>-0.958255</td>\n",
       "      <td>-1.128481</td>\n",
       "      <td>0.138336</td>\n",
       "      <td>0.980493</td>\n",
       "      <td>-0.932794</td>\n",
       "      <td>1.008313</td>\n",
       "      <td>-1.069627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.112376</td>\n",
       "      <td>-1.056574</td>\n",
       "      <td>1.741918</td>\n",
       "      <td>-1.504220</td>\n",
       "      <td>0.640009</td>\n",
       "      <td>1.081552</td>\n",
       "      <td>-1.182663</td>\n",
       "      <td>-0.461864</td>\n",
       "      <td>0.258321</td>\n",
       "      <td>-1.041546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.660647</td>\n",
       "      <td>-0.436981</td>\n",
       "      <td>0.775793</td>\n",
       "      <td>0.213394</td>\n",
       "      <td>-0.053171</td>\n",
       "      <td>2.030872</td>\n",
       "      <td>-1.240707</td>\n",
       "      <td>1.149298</td>\n",
       "      <td>2.184784</td>\n",
       "      <td>0.342811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.191324</td>\n",
       "      <td>-1.433473</td>\n",
       "      <td>-0.100053</td>\n",
       "      <td>-1.507223</td>\n",
       "      <td>-1.753632</td>\n",
       "      <td>-1.183561</td>\n",
       "      <td>-0.888557</td>\n",
       "      <td>0.162310</td>\n",
       "      <td>-0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099059</td>\n",
       "      <td>0.820815</td>\n",
       "      <td>-0.904346</td>\n",
       "      <td>1.609015</td>\n",
       "      <td>-0.282065</td>\n",
       "      <td>-0.365099</td>\n",
       "      <td>-1.095644</td>\n",
       "      <td>0.391419</td>\n",
       "      <td>-1.365603</td>\n",
       "      <td>0.787762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       XVPM      GWYH      TRAT      TLLZ      IGGA      HYKR      EDFS  \\\n",
       "0  1.568522 -0.443435  1.619808 -0.958255 -1.128481  0.138336  0.980493   \n",
       "1 -0.112376 -1.056574  1.741918 -1.504220  0.640009  1.081552 -1.182663   \n",
       "2  0.660647 -0.436981  0.775793  0.213394 -0.053171  2.030872 -1.240707   \n",
       "3  0.011533  0.191324 -1.433473 -0.100053 -1.507223 -1.753632 -1.183561   \n",
       "4 -0.099059  0.820815 -0.904346  1.609015 -0.282065 -0.365099 -1.095644   \n",
       "\n",
       "       GUUB      MGJM      JHZC  \n",
       "0 -0.932794  1.008313 -1.069627  \n",
       "1 -0.461864  0.258321 -1.041546  \n",
       "2  1.149298  2.184784  0.342811  \n",
       "3 -0.888557  0.162310 -0.002793  \n",
       "4  0.391419 -1.365603  0.787762  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918728dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XVPM</th>\n",
       "      <th>GWYH</th>\n",
       "      <th>TRAT</th>\n",
       "      <th>TLLZ</th>\n",
       "      <th>IGGA</th>\n",
       "      <th>HYKR</th>\n",
       "      <th>EDFS</th>\n",
       "      <th>GUUB</th>\n",
       "      <th>MGJM</th>\n",
       "      <th>JHZC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.568522</td>\n",
       "      <td>-0.443435</td>\n",
       "      <td>1.619808</td>\n",
       "      <td>-0.958255</td>\n",
       "      <td>-1.128481</td>\n",
       "      <td>0.138336</td>\n",
       "      <td>0.980493</td>\n",
       "      <td>-0.932794</td>\n",
       "      <td>1.008313</td>\n",
       "      <td>-1.069627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.112376</td>\n",
       "      <td>-1.056574</td>\n",
       "      <td>1.741918</td>\n",
       "      <td>-1.504220</td>\n",
       "      <td>0.640009</td>\n",
       "      <td>1.081552</td>\n",
       "      <td>-1.182663</td>\n",
       "      <td>-0.461864</td>\n",
       "      <td>0.258321</td>\n",
       "      <td>-1.041546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.660647</td>\n",
       "      <td>-0.436981</td>\n",
       "      <td>0.775793</td>\n",
       "      <td>0.213394</td>\n",
       "      <td>-0.053171</td>\n",
       "      <td>2.030872</td>\n",
       "      <td>-1.240707</td>\n",
       "      <td>1.149298</td>\n",
       "      <td>2.184784</td>\n",
       "      <td>0.342811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.191324</td>\n",
       "      <td>-1.433473</td>\n",
       "      <td>-0.100053</td>\n",
       "      <td>-1.507223</td>\n",
       "      <td>-1.753632</td>\n",
       "      <td>-1.183561</td>\n",
       "      <td>-0.888557</td>\n",
       "      <td>0.162310</td>\n",
       "      <td>-0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099059</td>\n",
       "      <td>0.820815</td>\n",
       "      <td>-0.904346</td>\n",
       "      <td>1.609015</td>\n",
       "      <td>-0.282065</td>\n",
       "      <td>-0.365099</td>\n",
       "      <td>-1.095644</td>\n",
       "      <td>0.391419</td>\n",
       "      <td>-1.365603</td>\n",
       "      <td>0.787762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.776682</td>\n",
       "      <td>0.758234</td>\n",
       "      <td>-1.753322</td>\n",
       "      <td>0.507699</td>\n",
       "      <td>0.174588</td>\n",
       "      <td>-1.279354</td>\n",
       "      <td>-1.797957</td>\n",
       "      <td>0.431419</td>\n",
       "      <td>0.088717</td>\n",
       "      <td>1.188886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.313446</td>\n",
       "      <td>0.385206</td>\n",
       "      <td>0.885502</td>\n",
       "      <td>-0.083136</td>\n",
       "      <td>-1.208486</td>\n",
       "      <td>0.309242</td>\n",
       "      <td>0.746346</td>\n",
       "      <td>-0.112571</td>\n",
       "      <td>-1.763636</td>\n",
       "      <td>-1.559081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.358895</td>\n",
       "      <td>-0.979015</td>\n",
       "      <td>0.837715</td>\n",
       "      <td>0.014018</td>\n",
       "      <td>-1.397424</td>\n",
       "      <td>0.054473</td>\n",
       "      <td>0.164120</td>\n",
       "      <td>-1.514726</td>\n",
       "      <td>-0.275122</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.275080</td>\n",
       "      <td>-0.992399</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>1.062954</td>\n",
       "      <td>1.142871</td>\n",
       "      <td>-0.192872</td>\n",
       "      <td>2.051386</td>\n",
       "      <td>-0.036233</td>\n",
       "      <td>0.436685</td>\n",
       "      <td>-0.212456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.625896</td>\n",
       "      <td>0.795109</td>\n",
       "      <td>1.121800</td>\n",
       "      <td>1.185944</td>\n",
       "      <td>0.555582</td>\n",
       "      <td>-1.133032</td>\n",
       "      <td>0.746559</td>\n",
       "      <td>-1.251565</td>\n",
       "      <td>-0.603529</td>\n",
       "      <td>-0.879859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         XVPM      GWYH      TRAT      TLLZ      IGGA      HYKR      EDFS  \\\n",
       "0    1.568522 -0.443435  1.619808 -0.958255 -1.128481  0.138336  0.980493   \n",
       "1   -0.112376 -1.056574  1.741918 -1.504220  0.640009  1.081552 -1.182663   \n",
       "2    0.660647 -0.436981  0.775793  0.213394 -0.053171  2.030872 -1.240707   \n",
       "3    0.011533  0.191324 -1.433473 -0.100053 -1.507223 -1.753632 -1.183561   \n",
       "4   -0.099059  0.820815 -0.904346  1.609015 -0.282065 -0.365099 -1.095644   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.776682  0.758234 -1.753322  0.507699  0.174588 -1.279354 -1.797957   \n",
       "996 -0.313446  0.385206  0.885502 -0.083136 -1.208486  0.309242  0.746346   \n",
       "997 -0.358895 -0.979015  0.837715  0.014018 -1.397424  0.054473  0.164120   \n",
       "998  0.275080 -0.992399  0.030371  1.062954  1.142871 -0.192872  2.051386   \n",
       "999  0.625896  0.795109  1.121800  1.185944  0.555582 -1.133032  0.746559   \n",
       "\n",
       "         GUUB      MGJM      JHZC  \n",
       "0   -0.932794  1.008313 -1.069627  \n",
       "1   -0.461864  0.258321 -1.041546  \n",
       "2    1.149298  2.184784  0.342811  \n",
       "3   -0.888557  0.162310 -0.002793  \n",
       "4    0.391419 -1.365603  0.787762  \n",
       "..        ...       ...       ...  \n",
       "995  0.431419  0.088717  1.188886  \n",
       "996 -0.112571 -1.763636 -1.559081  \n",
       "997 -1.514726 -0.275122  0.864287  \n",
       "998 -0.036233  0.436685 -0.212456  \n",
       "999 -1.251565 -0.603529 -0.879859  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1\n",
    "x=scaleddf\n",
    "y=df['TARGET CLASS']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "273ab832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db326a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe735d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sc=scaler.fit_transform(x_train)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e54c0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eae9a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "087b3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=knn.predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba9abe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b752f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2450a67",
   "metadata": {},
   "source": [
    "# 2 : Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "625518a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6616e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"E:\\internship\\heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b748737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc83b511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeb7fa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e45a0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c625b968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "119b0f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18d4878b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['XVPM', 'GWYH', 'TRAT', 'TLLZ', 'IGGA', 'HYKR', 'EDFS', 'GUUB', 'MGJM',\n",
       "       'JHZC', 'TARGET CLASS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e1f4524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XVPM</th>\n",
       "      <th>GWYH</th>\n",
       "      <th>TRAT</th>\n",
       "      <th>TLLZ</th>\n",
       "      <th>IGGA</th>\n",
       "      <th>HYKR</th>\n",
       "      <th>EDFS</th>\n",
       "      <th>GUUB</th>\n",
       "      <th>MGJM</th>\n",
       "      <th>JHZC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.568522</td>\n",
       "      <td>-0.443435</td>\n",
       "      <td>1.619808</td>\n",
       "      <td>-0.958255</td>\n",
       "      <td>-1.128481</td>\n",
       "      <td>0.138336</td>\n",
       "      <td>0.980493</td>\n",
       "      <td>-0.932794</td>\n",
       "      <td>1.008313</td>\n",
       "      <td>-1.069627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.112376</td>\n",
       "      <td>-1.056574</td>\n",
       "      <td>1.741918</td>\n",
       "      <td>-1.504220</td>\n",
       "      <td>0.640009</td>\n",
       "      <td>1.081552</td>\n",
       "      <td>-1.182663</td>\n",
       "      <td>-0.461864</td>\n",
       "      <td>0.258321</td>\n",
       "      <td>-1.041546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.660647</td>\n",
       "      <td>-0.436981</td>\n",
       "      <td>0.775793</td>\n",
       "      <td>0.213394</td>\n",
       "      <td>-0.053171</td>\n",
       "      <td>2.030872</td>\n",
       "      <td>-1.240707</td>\n",
       "      <td>1.149298</td>\n",
       "      <td>2.184784</td>\n",
       "      <td>0.342811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.191324</td>\n",
       "      <td>-1.433473</td>\n",
       "      <td>-0.100053</td>\n",
       "      <td>-1.507223</td>\n",
       "      <td>-1.753632</td>\n",
       "      <td>-1.183561</td>\n",
       "      <td>-0.888557</td>\n",
       "      <td>0.162310</td>\n",
       "      <td>-0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099059</td>\n",
       "      <td>0.820815</td>\n",
       "      <td>-0.904346</td>\n",
       "      <td>1.609015</td>\n",
       "      <td>-0.282065</td>\n",
       "      <td>-0.365099</td>\n",
       "      <td>-1.095644</td>\n",
       "      <td>0.391419</td>\n",
       "      <td>-1.365603</td>\n",
       "      <td>0.787762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.776682</td>\n",
       "      <td>0.758234</td>\n",
       "      <td>-1.753322</td>\n",
       "      <td>0.507699</td>\n",
       "      <td>0.174588</td>\n",
       "      <td>-1.279354</td>\n",
       "      <td>-1.797957</td>\n",
       "      <td>0.431419</td>\n",
       "      <td>0.088717</td>\n",
       "      <td>1.188886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.313446</td>\n",
       "      <td>0.385206</td>\n",
       "      <td>0.885502</td>\n",
       "      <td>-0.083136</td>\n",
       "      <td>-1.208486</td>\n",
       "      <td>0.309242</td>\n",
       "      <td>0.746346</td>\n",
       "      <td>-0.112571</td>\n",
       "      <td>-1.763636</td>\n",
       "      <td>-1.559081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.358895</td>\n",
       "      <td>-0.979015</td>\n",
       "      <td>0.837715</td>\n",
       "      <td>0.014018</td>\n",
       "      <td>-1.397424</td>\n",
       "      <td>0.054473</td>\n",
       "      <td>0.164120</td>\n",
       "      <td>-1.514726</td>\n",
       "      <td>-0.275122</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.275080</td>\n",
       "      <td>-0.992399</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>1.062954</td>\n",
       "      <td>1.142871</td>\n",
       "      <td>-0.192872</td>\n",
       "      <td>2.051386</td>\n",
       "      <td>-0.036233</td>\n",
       "      <td>0.436685</td>\n",
       "      <td>-0.212456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.625896</td>\n",
       "      <td>0.795109</td>\n",
       "      <td>1.121800</td>\n",
       "      <td>1.185944</td>\n",
       "      <td>0.555582</td>\n",
       "      <td>-1.133032</td>\n",
       "      <td>0.746559</td>\n",
       "      <td>-1.251565</td>\n",
       "      <td>-0.603529</td>\n",
       "      <td>-0.879859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         XVPM      GWYH      TRAT      TLLZ      IGGA      HYKR      EDFS  \\\n",
       "0    1.568522 -0.443435  1.619808 -0.958255 -1.128481  0.138336  0.980493   \n",
       "1   -0.112376 -1.056574  1.741918 -1.504220  0.640009  1.081552 -1.182663   \n",
       "2    0.660647 -0.436981  0.775793  0.213394 -0.053171  2.030872 -1.240707   \n",
       "3    0.011533  0.191324 -1.433473 -0.100053 -1.507223 -1.753632 -1.183561   \n",
       "4   -0.099059  0.820815 -0.904346  1.609015 -0.282065 -0.365099 -1.095644   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.776682  0.758234 -1.753322  0.507699  0.174588 -1.279354 -1.797957   \n",
       "996 -0.313446  0.385206  0.885502 -0.083136 -1.208486  0.309242  0.746346   \n",
       "997 -0.358895 -0.979015  0.837715  0.014018 -1.397424  0.054473  0.164120   \n",
       "998  0.275080 -0.992399  0.030371  1.062954  1.142871 -0.192872  2.051386   \n",
       "999  0.625896  0.795109  1.121800  1.185944  0.555582 -1.133032  0.746559   \n",
       "\n",
       "         GUUB      MGJM      JHZC  \n",
       "0   -0.932794  1.008313 -1.069627  \n",
       "1   -0.461864  0.258321 -1.041546  \n",
       "2    1.149298  2.184784  0.342811  \n",
       "3   -0.888557  0.162310 -0.002793  \n",
       "4    0.391419 -1.365603  0.787762  \n",
       "..        ...       ...       ...  \n",
       "995  0.431419  0.088717  1.188886  \n",
       "996 -0.112571 -1.763636 -1.559081  \n",
       "997 -1.514726 -0.275122  0.864287  \n",
       "998 -0.036233  0.436685 -0.212456  \n",
       "999 -1.251565 -0.603529 -0.879859  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1\n",
    "\n",
    "X = data.drop(['target'], axis = 1)# axis  = 1 for columns\n",
    "y = data['target']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53a32e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : (302, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f'X : {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8190b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "528bc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest Model with hyperparameters\n",
    "#step 3\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,4]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32b0af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 17, 25, 33, 41, 48, 56, 64, 72, 80], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 4], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Create the param grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12048d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10bfc0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_Grid = GridSearchCV(estimator = rf_Model, param_grid = param_grid, cv = 3, verbose=2, n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8136cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "480 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "192 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "288 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.81347737 0.83420782\n",
      " 0.80087449 0.81332305 0.81342593 0.83410494 0.83004115 0.8382716\n",
      " 0.82582305 0.8215535  0.80493827 0.80087449 0.81748971 0.81748971\n",
      " 0.84243827 0.82165638 0.85066872 0.82582305 0.84238683 0.8340535\n",
      " 0.82170782 0.80504115 0.82165638 0.8132716  0.82582305 0.82170782\n",
      " 0.84233539 0.8465535  0.81754115 0.81754115 0.79665638 0.80925926\n",
      " 0.80925926 0.81743827 0.8215535  0.83410494 0.82998971 0.81332305\n",
      " 0.82587449 0.81743827        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.80915638 0.79264403 0.80920782 0.81342593 0.83004115 0.82582305\n",
      " 0.80915638 0.84243827 0.81743827 0.83410494 0.79254115 0.82170782\n",
      " 0.82165638 0.81759259 0.82993827 0.80087449 0.83410494 0.82170782\n",
      " 0.83410494 0.8340535  0.8257716  0.82160494 0.84254115 0.82993827\n",
      " 0.81748971 0.83395062 0.81332305 0.81743827 0.83410494 0.8257716\n",
      " 0.80504115 0.8090535  0.80910494 0.81342593 0.84665638 0.81754115\n",
      " 0.82165638 0.83822016 0.8257716  0.82170782        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.79686214 0.81748971 0.81754115 0.81342593\n",
      " 0.8257716  0.81748971 0.81342593 0.81332305 0.8257716  0.82582305\n",
      " 0.77592593 0.80920782 0.82993827 0.80920782 0.80082305 0.82165638\n",
      " 0.81748971 0.82983539 0.81347737 0.8257716  0.79675926 0.81748971\n",
      " 0.80092593 0.81754115 0.80925926 0.84248971 0.80900206 0.81748971\n",
      " 0.8340535  0.82993827 0.77201646 0.7968107  0.82165638 0.81748971\n",
      " 0.82170782 0.83420782 0.8257716  0.83410494 0.81748971 0.81743827\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.82993827 0.80514403\n",
      " 0.80504115 0.80504115 0.81743827 0.82175926 0.82998971 0.8132716\n",
      " 0.81342593 0.8340535  0.79254115 0.79264403 0.81748971 0.81337449\n",
      " 0.82998971 0.81332305 0.82592593 0.81754115 0.82165638 0.84238683\n",
      " 0.80493827 0.80519547 0.82993827 0.8215535  0.82988683 0.83004115\n",
      " 0.82587449 0.82170782 0.82160494 0.81748971 0.80925926 0.78847737\n",
      " 0.81769547 0.81743827 0.8132716  0.78847737 0.82160494 0.80514403\n",
      " 0.82993827 0.82993827]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [2, 4],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [10, 17, 25, 33, 41, 48, 56, 64, 72,\n",
       "                                          80]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [2, 4],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [10, 17, 25, 33, 41, 48, 56, 64, 72,\n",
       "                                          80]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [2, 4],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [10, 17, 25, 33, 41, 48, 56, 64, 72,\n",
       "                                          80]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c15f03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 56}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d2d0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy - : 0.867\n",
      "Test Accuracy - : 0.852\n"
     ]
    }
   ],
   "source": [
    "#step 4 \n",
    "#checking accuracy\n",
    "\n",
    "print (f'Train Accuracy - : {rf_Grid.score(X_train,y_train):.3f}')\n",
    "print (f'Test Accuracy - : {rf_Grid.score(X_test,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6679b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
